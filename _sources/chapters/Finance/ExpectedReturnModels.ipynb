{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspected-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf53ae",
   "metadata": {},
   "source": [
    "# Factor Models as Models of Expected Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d4036",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "So far we had \n",
    "\n",
    "$$r_t^i=b_{i,1}f_t^1+b_{i,2}f_t^2+b_{i,3}f_t^3+...+b_{i,M}f_t^M+u_{i,t}$$\n",
    "\n",
    "\n",
    "- Where we made assumptions about how $u_{i,t}$ was uncorrelated across assets (i.e. across i)\n",
    "\n",
    "- But we made NO assumption about any risk-premium in $u_{i,t}$, i.e $E[u_{i,t}]$ does not need to be equal to zero\n",
    "\n",
    "- In fact we added a constant when we estimated the model to keep this parameter free\n",
    "\n",
    "- A model of expected returns is exactly the opposite\n",
    "\n",
    "- We will relax the assumption that the $u_{i,t}$ are uncorrelated--they will be free to do whatever, but\n",
    "\n",
    "- We will impose that they have no risk-premium, i.e. $E[u_{i,t}]=0$ for any asset $i$\n",
    "\n",
    "\n",
    "- If this restriction is true, when we take expectations in both sides we get\n",
    "\n",
    "$$E[r_t^i]=\\sum_j^M b_{i,j}E[f_t^j]+E[u_{i,t}]=\\sum_j^M b_{i,j}E[f_t^j]$$\n",
    "\n",
    "- Thus the exposures together with the factor risk-premium are all we need to know to know the expected return of a given asset\n",
    "\n",
    "- It means that if the model is right ( it never is! It is a model!An approximation) All the premium that there is has to be harvested from these factors alone\n",
    "\n",
    "\n",
    "- It also means that any portfolio that has any risk $\\sigma(u_{i,t})>0$ is not mean-variance efficient\n",
    "\n",
    "- Why? Because this $\\sigma(u_{i,t})$ adds vol, but does not add premium so it must have a lower Sharpe ratio than a portfolio that has the same loadings but no idio risk\n",
    "\n",
    "\n",
    "- It also tell us that a portfolio of the factors spam (meaning you can combine them to obtaim) the maximum Sharpe Ratio portfolio\n",
    "\n",
    "- Just as before, our model is a linear regression with a very important restriction--the intercept must be zero for the model to be right\n",
    "\n",
    "## Alpha\n",
    "\n",
    "for clarity lets focus on the single factor case M=1. Say we run the regression\n",
    "\n",
    "$$r^i_t=\\alpha_i +\\beta_{i}f_t +\\epsilon_{i,t}$$\n",
    "\n",
    "- Then this relation predicts that the intercept, the alpha, should be zero\n",
    "\n",
    "- It is important here that both the test assets and the reference portfolios are all **excess returns**. This makes the test really simple. If you use returns instead the prediction about the intercept will be different because of the risk-free rate\n",
    "\n",
    "- We refer to these assets on the Left Hand Side of the regression as **Test Assets** and the asset on the right as the **model**, which is the candidate factor model ( that can contain one or many more factors)\n",
    "\n",
    "- This means that we can use this to test whether a new strategy adds value relative to another strategy (i.e. the model).\n",
    "\n",
    "- If the model is \"right\" than we will fail to reject that the alphas are zero, i.e. the relationship between average returns and factor exposures and factor premiums hold.\n",
    "\n",
    "- Why alpha=0 is so special? Because it tells us that the expected return of any of these assets can be captured by varying the exposure to  the factor with the minimum increase in risk possible\n",
    "\n",
    "**What adding value means?** It means that the test portfolio can increase the  sharpe ratio of the maximum sharpe ratio portfolio spanned by the factors. So it means that this asset increases the opportunity set of an investor that has access to the factors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### CAPM\n",
    "\n",
    "CAPM prediction: Market portfolio is the mean-varaince efficient portfolio\n",
    "\n",
    "\n",
    "* The most used reference portfolio is the market portfolio\n",
    "\n",
    "* So we will do our first alpha test with respect to the market\n",
    "\n",
    "* The CAPM holds for a set of assets i=1...N if and only if\n",
    "\n",
    "\n",
    "  $$E[r_{i,t}] =\\alpha_i+\\beta_{i,MKT} E[r_{t}^{MKT}]$$\n",
    "  \n",
    "  with $\\alpha_i=0$ for all assets  i=1...N\n",
    "\n",
    "  Where both $r_{i,t}$ and $r_{t}^{MKT}$ are excess returns\n",
    " \n",
    "\n",
    "\n",
    "* So if you put any other factor= instead of the market excess return, then you are not testing the CAPM. The CAPM is a specific model that predicts that the market is tangency--in fact the model predicts that is the excess return on the total wealth portfolio--so it is really untestable!\n",
    "\n",
    "It is very important here that is all about expectations, not at all about realized returns. \n",
    "\n",
    "Being MVE does **NOT** mean that your realized returns should explain all the other realized returns. The idio risk can be quite large and can even be correlated across assets!\n",
    "\n",
    "Instead, it means that the betas of the asset with the factor should explain the expected return of the asset.\n",
    "\n",
    "Of course, stuff happens, so even if your reference portfolio is in fact MVE portfolio under the true distribution, it will not be in any particular sample, so we will use statistics to tell us if the $\\alpha$ is different enough from zero.\n",
    "\n",
    "\n",
    "\n",
    "**Why practitioners care about this? Beating the Model**\n",
    "\n",
    " Practicioners use this to see if they can beat the CAPM (or any richer factor model), i.e. **beat the market**. Having an alpha--a postive intercept-- means that you have an average return that is higher than your strategy market risk exposure would predict.\n",
    "\n",
    "\n",
    "So if you are U of R  endowment, and a big shot hedge fund manager comes and pitch some fund with some large Sharpe ratio---all you should want to know is whether after you adjust for the exposures to the expected return factors that you already know, if this guys still has alpha.\n",
    "\n",
    "His value added to you is only the alpha--not the entire Sharpe ratio\n",
    "\n",
    "Why? Because the other stuff you already know how to harvest the premium\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2aba09",
   "metadata": {},
   "source": [
    "## Testing  if $\\alpha_i \\neq 0$\n",
    "\n",
    "  - Our test will be agnostic on the direction.\n",
    "> Can a negative alpha be value enhancing? Is it likely to be value enhancing in the case of a hedge fund pitching the UofR endowment? \n",
    "\n",
    "  - After running the regression with a free intercept you do a standard t-test \n",
    "\n",
    "  $$t=\\frac{\\alpha_i }{\\sigma(\\alpha_i)}$$\n",
    "\n",
    "* We say\n",
    "\n",
    " - if $|t|\\geq 1.64$ there is a 10% chance that the factor is MVE\n",
    " - if $|t|\\geq 1.96$ there is a 5% chance that the factor is MVE\n",
    " - if $|t|\\geq 2.1$ there is a 2.5% chance that the factor is MVE\n",
    " - if $|t|\\geq 2.6$ there is a 1% chance that the factor is MVE\n",
    " \n",
    " \n",
    "* The Time-series regression asks the following question:\n",
    "  \n",
    "> Can I replicate  the average return I get in asset/strategy $i$ by investing in the factor/factors on the right?\n",
    "\n",
    " \n",
    "* It mean that you can do better by investing by adding asset $i$ to your investment mix\n",
    "\n",
    "> Question: I show that Asset A has alpha with respect to Asset B. Does it mean that an investor should prefer asset A to asset B?\n",
    "\n",
    "## Application: Does Warren Buffet beats the market?\n",
    "\n",
    "![fig](../../assets/plots/WB_image.jpg)\n",
    "\n",
    "Warren Buffett is the chairman and CEO of Berkshire Hathaway, a multinational conglomerate holding company. Berkshire Hathaway's portfolio includes a diverse range of companies, but its five largest positions are in Apple Inc., Bank of America Corp, Chevron, The Coca-Cola Company, and American Express Company. Buffett is known for his extraordinary performance record and his transparent, straightforward investment model, which involves investing in large, blue-chip companies with strong balance sheets and attractive valuations. His investment strategy focuses on long-term investments and he is recognized for making significant new investments while also being unafraid to drop longtime holdings. As of 2022, Buffett's largest holding was in Apple Inc., representing 41.76% of the equity portfolio, with an estimated gain of 246.02%. Berkshire Hathaway is a leading conglomerate due to Buffett's business savvy and investing, with a high rate of return and a portfolio that continues to attract wide media attention and scrutiny.\n",
    "\n",
    "\n",
    "\n",
    "Citations:\n",
    "[1] https://en.wikipedia.org/wiki/Warren_Buffett\n",
    "[2] https://www.berkshirehathaway.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfec142",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bce7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('../../assets/data/df_WarrenBAndCathieW.pkl')\n",
    "# select the columns to use as factors\n",
    "Factors=df.drop(['BRK','RF','ARKK'],axis=1)\n",
    "Factors.head(3)\n",
    "BrK=df.BRK-df.RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac6afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   79.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 02 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>7.17e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:37:53</td>     <th>  Log-Likelihood:    </th> <td>  442.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   279</td>      <th>  AIC:               </th> <td>  -880.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   277</td>      <th>  BIC:               </th> <td>  -873.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>    0.0054</td> <td>    0.003</td> <td>    1.797</td> <td> 0.073</td> <td>   -0.001</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mkt-RF</th> <td>    0.5919</td> <td>    0.066</td> <td>    8.906</td> <td> 0.000</td> <td>    0.461</td> <td>    0.723</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>51.668</td> <th>  Durbin-Watson:     </th> <td>   1.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 198.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.710</td> <th>  Prob(JB):          </th> <td>7.59e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.882</td> <th>  Cond. No.          </th> <td>    22.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.223\n",
       "Model:                            OLS   Adj. R-squared:                  0.220\n",
       "Method:                 Least Squares   F-statistic:                     79.32\n",
       "Date:                Fri, 02 Feb 2024   Prob (F-statistic):           7.17e-17\n",
       "Time:                        11:37:53   Log-Likelihood:                 442.23\n",
       "No. Observations:                 279   AIC:                            -880.5\n",
       "Df Residuals:                     277   BIC:                            -873.2\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0054      0.003      1.797      0.073      -0.001       0.011\n",
       "Mkt-RF         0.5919      0.066      8.906      0.000       0.461       0.723\n",
       "==============================================================================\n",
       "Omnibus:                       51.668   Durbin-Watson:                   1.989\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              198.575\n",
       "Skew:                           0.710   Prob(JB):                     7.59e-44\n",
       "Kurtosis:                       6.882   Cond. No.                         22.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "x= sm.add_constant(df['Mkt-RF'])\n",
    "\n",
    "results= sm.OLS(BrK,x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089d2b5",
   "metadata": {},
   "source": [
    "* what do we learn? \n",
    "\n",
    "* how to think about this alpha? Is it large? \n",
    "\n",
    "* Is it large economically?\n",
    "\n",
    "* is it large statistically?\n",
    "\n",
    "\n",
    "Now lets use a multi-factor model\n",
    "\n",
    "\n",
    "**Which Multi-factor model?**\n",
    "\n",
    "\n",
    "1. Fama French 3 factor model:\n",
    "\n",
    "$$E[R_t^i-R_t^f]=\\beta_{i,mkt}E[R^{mkt}_t-R^f_t]+\\beta_{i,smb}E[SmB_t]+\\beta_{i,HmL}E[HmL_t]$$\n",
    "\n",
    "2. Carhart 4 factor model:\n",
    "\n",
    "$$E[R_t^i-R_t^f]=\\beta_{i,mkt}E[R^{mkt}_t-R^f_t]+\\beta_{i,smb}E[SmB_t]+\\beta_{i,HmL}E[HmL_t]+\\beta_{i,WmL}E[WmL_t]$$\n",
    "\n",
    "3. Fama French  5 factor model:\n",
    "\n",
    "$$E[R_t^i-R_t^f]=\\beta_{i,mkt}E[R^{mkt}_t-R^f_t]+\\beta_{i,smb}E[SmB_t]+\\beta_{i,HmL}E[HmL_t]+\\beta_{i,rmw}E[RmW_t]+\\beta_{i,cma}E[CmA_t]$$\n",
    "\n",
    "4. Fama French  5 factor model + Momentum:\n",
    "\n",
    "$$E[R_t^i-R_t^f]=\\beta_{i,mkt}E[R^{mkt}_t-R^f_t]+\\beta_{i,smb}E[SmB_t]+\\beta_{i,HmL}E[HmL_t]+\\beta_{i,rmw}E[RmW_t]+\\beta_{i,cma}E[CmA_t]+\\beta_{i,WmL}E[WmL_t]$$\n",
    "\n",
    "\n",
    "These models are more or less on chronological order.\n",
    "\n",
    "Most practicioners today would start with the 6 factor model and if they are dealing with non equity assets add a bunch of asset class specific factors that essentially mimic some of these factors in these spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "552dd469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.291</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.291</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   570.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 02 Feb 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:39:18</td>     <th>  Log-Likelihood:    </th>  <td>  24961.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8338</td>      <th>  AIC:               </th> <td>-4.991e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8331</td>      <th>  BIC:               </th> <td>-4.986e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>    0.0003</td> <td>    0.000</td> <td>    2.295</td> <td> 0.022</td> <td> 4.46e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mkt-RF</th> <td>    0.6296</td> <td>    0.013</td> <td>   47.908</td> <td> 0.000</td> <td>    0.604</td> <td>    0.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SMB</th>    <td>   -0.1003</td> <td>    0.024</td> <td>   -4.236</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HML</th>    <td>    0.4461</td> <td>    0.027</td> <td>   16.835</td> <td> 0.000</td> <td>    0.394</td> <td>    0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMW</th>    <td>   -0.1677</td> <td>    0.032</td> <td>   -5.263</td> <td> 0.000</td> <td>   -0.230</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CMA</th>    <td>   -0.0608</td> <td>    0.041</td> <td>   -1.469</td> <td> 0.142</td> <td>   -0.142</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mom   </th> <td>    0.0338</td> <td>    0.017</td> <td>    2.000</td> <td> 0.045</td> <td>    0.001</td> <td>    0.067</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2249.754</td> <th>  Durbin-Watson:     </th> <td>   2.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>45256.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.794</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>14.302</td>  <th>  Cond. No.          </th> <td>    338.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.291\n",
       "Model:                            OLS   Adj. R-squared:                  0.291\n",
       "Method:                 Least Squares   F-statistic:                     570.7\n",
       "Date:                Fri, 02 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        11:39:18   Log-Likelihood:                 24961.\n",
       "No. Observations:                8338   AIC:                        -4.991e+04\n",
       "Df Residuals:                    8331   BIC:                        -4.986e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0003      0.000      2.295      0.022    4.46e-05       0.001\n",
       "Mkt-RF         0.6296      0.013     47.908      0.000       0.604       0.655\n",
       "SMB           -0.1003      0.024     -4.236      0.000      -0.147      -0.054\n",
       "HML            0.4461      0.027     16.835      0.000       0.394       0.498\n",
       "RMW           -0.1677      0.032     -5.263      0.000      -0.230      -0.105\n",
       "CMA           -0.0608      0.041     -1.469      0.142      -0.142       0.020\n",
       "Mom            0.0338      0.017      2.000      0.045       0.001       0.067\n",
       "==============================================================================\n",
       "Omnibus:                     2249.754   Durbin-Watson:                   2.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            45256.687\n",
       "Skew:                           0.794   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.302   Cond. No.                         338.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=df.copy() \n",
    "Factors=df.drop(['BRK','RF','ARKK'],axis=1)\n",
    "x= sm.add_constant(Factors)\n",
    "y= df.BRK-df.RF\n",
    "results= sm.OLS(y,x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17017413",
   "metadata": {},
   "source": [
    "Now lets look at monthly data\n",
    "\n",
    "\n",
    "- Do you think the results will change?\n",
    "\n",
    "- What can happen?\n",
    "\n",
    "- Are the exposures comparable?\n",
    "\n",
    "- Are the alphas comparable?\n",
    "\n",
    "- How to make them comparable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2e68be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_pickle('../../assets/data/df_WarrenBAndCathieW_monthly.pkl')\n",
    "# # select the columns to use as factors\n",
    "# Factors=df.drop(['BRK','RF','ARKK'],axis=1)\n",
    "# Factors.head(3)\n",
    "# BrK=df.BRK-df.RF\n",
    "\n",
    "# temp=df.copy() \n",
    "# Factors=df.drop(['BRK','RF','ARKK'],axis=1)\n",
    "# x= sm.add_constant(Factors)\n",
    "# y= df.BRK-df.RF\n",
    "# results= sm.OLS(y,x).fit()\n",
    "# results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd992f",
   "metadata": {},
   "source": [
    "* what do we learn now? Did it make any difference? \n",
    "* what kind of stocks Warren likes?\n",
    "* What do we learn about Warren Investment style?\n",
    "* What do we learn about Warren specific stock picking skills?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c210edf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Portable Alpha and Hedged Portfolios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d113d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a680e11",
   "metadata": {},
   "source": [
    "## Appraisal Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d27370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b660b610",
   "metadata": {},
   "source": [
    "## Multi-factor: theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-alpha",
   "metadata": {
    "colab_type": "text",
    "id": "bzWl3blrhHrz"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "What about the theory?\n",
    "\n",
    "### IT is the CAPM, but the wealth portfolio is not the stock market\n",
    "\n",
    "* According to the  CAPM the Wealth portfolio is the tangency portfolio\n",
    "\n",
    "* The return on the wealth portfolio summarizes how Bad the times are\n",
    "\n",
    "* Assets that co-vary more with the market must earn higher returns\n",
    "\n",
    "* They pay poorly exactly when things are worse\n",
    "\n",
    "* What is the wealth portfolio? It is the portfolio that holds all assets in proportion to their value\n",
    "\n",
    "* We often use the equity market as a proxy for this, but that is not the CAPM\n",
    "\n",
    "* In a way that CAPM is untestable because it is impossible to construct the true wealth portfolio\n",
    "\n",
    "\n",
    "* The fact that we cannot really measure the returns of the total wealth portfolio gives us a reason to add other facts in additions to the returns to the equity market. Under this logic you add returns to other assets classes>\n",
    "       \n",
    "  - Real estate\n",
    "  - Corporate debt\n",
    "  - Human capital\n",
    "  - Private equity\n",
    "  - Venture Capital\n",
    "  -...\n",
    "\n",
    "So you get:\n",
    "\n",
    "$$E[R_t^i-R_t^f]=\\beta_{i,mkt}E[R^{mkt}_t-R^f_t]+\\sum_a^A\\beta_{i,a}E[R^{a}_t-R^f_t]$$\n",
    "\n",
    "* where $a$ are the different asset classes.\n",
    "\n",
    "* Sometimes people refer to these other hard to trade assets as \"background risks\", basically risks that are you are exposed to that are not capture by your financial assets\n",
    "\n",
    "### ICAPM: Intertemporal Capital Asset Pricing Model\n",
    " \n",
    "* Another way to rationalize additional  factors is to realize that the premium and the volatility of the market are time-varying.\n",
    "\n",
    "* This means that assets that allow you to hedge this investment opportunity set risk will be valuable\n",
    "\n",
    "   - For example, an asset that pays well when the market is more/less volatile or one that pays well when the expected returns of market going froward are higher/lower\n",
    "   \n",
    "* Under this logic, any strategy that is related to the market moments can also explain average returns on top of the marker beta\n",
    "\n",
    "* Sometimes people refer to the background risks discussed earlier in this framework as well. But in this case it is not about the moments of the market portfolio per se, but about correlation of the strategy with the background risks investors bear\n",
    "\n",
    "* The end result is the same\n",
    "\n",
    "$$E[R_t^i-R_t^f]=\\beta_{i,mkt}E[R^{mkt}_t-R^f_t]+\\sum_{j=1}^J\\beta_{i,j}E[Factor^j_t]$$\n",
    "\n",
    "\n",
    "* but now these are \"Factors\" and do no need to be components of the total wealth\n",
    "\n",
    "* but these factors must still be excess returns, i.e. they must be strategies based on financial assets that have price zero\n",
    "\n",
    "### APT: Arbitrage Pricing Theory\n",
    "\n",
    "\n",
    "* This is probably the most popular and more flexible way to think about multi-factor models\n",
    "\n",
    "* but now the factors are motivated because the explain time-series variation in realized return\n",
    "\n",
    "* the idea is that if you have enough factors you explain enough of the variation in the returns of an asset that if the betas do no explain the average returns than an arbitrage opportunity wouldd open up\n",
    "\n",
    "* If you have a good enough model of RISK--then by arbitrage --you better have a good model of expected returns!\n",
    "\n",
    "* Essentially they idea is that if\n",
    "\n",
    "$$R_t^i-R_t^f=\\sum_{j=1}^J\\beta_{i,j}Factor^j_t+u_{i,t}$$\n",
    "\n",
    "\n",
    "where $\\sigma(u)$ is small , then \n",
    "\n",
    "$$E[R_t^i-R_t^f]\\approx\\sum_{j=1}^J\\beta_{i,j}E[Factor^j_t]$$\n",
    "\n",
    "* otherwise Sharpe ratio of going long/short the asset and short/long the model would be huge since\n",
    "\n",
    "\n",
    "$$E[u_{i,t}]=E[R_t^i-R_t^f]-\\sum_{j=1}^J\\beta_{i,j}E[Factor^j_t]$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
